{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5893ac8b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Utilities\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a417490",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Dataset\n",
    "\n",
    "Load all UNSW-NB15 CSV files and combine them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load all CSV files from data/ directory\n",
    "# data_files = glob.glob('../data/UNSW-NB15_*.csv')\n",
    "# df = pd.concat([pd.read_csv(file) for file in sorted(data_files)], ignore_index=True)\n",
    "\n",
    "# TODO: Display basic info\n",
    "# print(f\"Total records: {len(df):,}\")\n",
    "# print(f\"Total features: {df.shape[1]}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2e516",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d721f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check data types\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ded62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for missing values\n",
    "# missing = df.isnull().sum()\n",
    "# missing[missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summary statistics for numerical features\n",
    "# df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46eb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check categorical features\n",
    "# categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "# print(f\"Categorical features: {list(categorical_cols)}\")\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
    "#     print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb553d8a",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Univariate Analysis & Outlier Detection\n",
    "\n",
    "Analyze individual features and detect outliers using IQR method and Z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5220151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select numerical columns for analysis\n",
    "# numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# # Remove id and label columns if present\n",
    "# numerical_cols = [col for col in numerical_cols if col not in ['id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a50cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Outlier detection using IQR method\n",
    "# def detect_outliers_iqr(data, column):\n",
    "#     \"\"\"Detect outliers using Interquartile Range method\"\"\"\n",
    "#     Q1 = data[column].quantile(0.25)\n",
    "#     Q3 = data[column].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "#     return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "# # Apply to all numerical columns\n",
    "# outlier_summary = {}\n",
    "# for col in numerical_cols[:10]:  # First 10 features as example\n",
    "#     count, lb, ub = detect_outliers_iqr(df, col)\n",
    "#     outlier_summary[col] = {'count': count, 'percentage': (count/len(df))*100}\n",
    "\n",
    "# pd.DataFrame(outlier_summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f347c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize distributions with box plots\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# for idx, col in enumerate(numerical_cols[:9]):\n",
    "#     sns.boxplot(data=df, y=col, ax=axes[idx])\n",
    "#     axes[idx].set_title(f'{col} - Outlier Detection')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../outputs/univariate_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Distribution plots (histograms)\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# for idx, col in enumerate(numerical_cols[:9]):\n",
    "#     axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "#     axes[idx].set_title(f'{col} Distribution')\n",
    "#     axes[idx].set_xlabel(col)\n",
    "#     axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../outputs/univariate_histograms.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e186b99",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Bivariate Analysis\n",
    "\n",
    "Explore relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ccf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare feature distributions by label (Normal vs Attack)\n",
    "# sample_features = numerical_cols[:6]\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# for idx, col in enumerate(sample_features):\n",
    "#     for label in df['label'].unique():\n",
    "#         subset = df[df['label'] == label][col].dropna()\n",
    "#         axes[idx].hist(subset, alpha=0.6, label=f'Label {label}', bins=30)\n",
    "#     axes[idx].set_title(f'{col} by Label')\n",
    "#     axes[idx].legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../outputs/bivariate_analysis.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79406150",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Correlation Analysis\n",
    "\n",
    "Generate correlation heatmap to identify multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute correlation matrix\n",
    "# correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# # Plot heatmap\n",
    "# plt.figure(figsize=(20, 16))\n",
    "# sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "#             square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "# plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../outputs/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find highly correlated feature pairs (|correlation| > 0.8)\n",
    "# high_corr_pairs = []\n",
    "# for i in range(len(correlation_matrix.columns)):\n",
    "#     for j in range(i+1, len(correlation_matrix.columns)):\n",
    "#         if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "#             high_corr_pairs.append({\n",
    "#                 'Feature 1': correlation_matrix.columns[i],\n",
    "#                 'Feature 2': correlation_matrix.columns[j],\n",
    "#                 'Correlation': correlation_matrix.iloc[i, j]\n",
    "#             })\n",
    "\n",
    "# pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f5bfc",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eca9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check class balance\n",
    "# label_counts = df['label'].value_counts()\n",
    "# print(\"Target Variable Distribution:\")\n",
    "# print(label_counts)\n",
    "# print(f\"\\nClass Balance: {label_counts[1]/label_counts[0]:.2%} (Attack/Normal)\")\n",
    "\n",
    "# # Visualization\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# # Count plot\n",
    "# label_counts.plot(kind='bar', ax=ax1, color=['#2ecc71', '#e74c3c'])\n",
    "# ax1.set_title('Target Variable Distribution', fontsize=14, fontweight='bold')\n",
    "# ax1.set_xlabel('Label (0=Normal, 1=Attack)')\n",
    "# ax1.set_ylabel('Count')\n",
    "# ax1.set_xticklabels(['Normal', 'Attack'], rotation=0)\n",
    "\n",
    "# # Pie chart\n",
    "# ax2.pie(label_counts, labels=['Normal', 'Attack'], autopct='%1.1f%%', \n",
    "#         colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
    "# ax2.set_title('Class Distribution Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../outputs/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d45d61",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Key Insights & Next Steps\n",
    "\n",
    "### Summary of Findings:\n",
    "- **Dataset Size:** [Fill in after loading]\n",
    "- **Missing Values:** [Summarize]\n",
    "- **Outliers:** [Summarize percentage]\n",
    "- **Class Balance:** [Indicate if imbalanced]\n",
    "- **Multicollinearity:** [List highly correlated features]\n",
    "\n",
    "### Action Items for Next Notebook:\n",
    "1. ✅ Handle missing values (imputation or removal)\n",
    "2. ✅ Address outliers (capping, transformation, or removal)\n",
    "3. ✅ Feature engineering (new features, interactions)\n",
    "4. ✅ Encode categorical variables\n",
    "5. ✅ Feature scaling/normalization\n",
    "6. ✅ Handle class imbalance if needed\n",
    "\n",
    "---\n",
    "**Proceed to:** `02_preprocessing_feature_engineering.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
